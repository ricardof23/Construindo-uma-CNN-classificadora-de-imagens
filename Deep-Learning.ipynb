# Bibliotecas
from tensorflow import keras
import tensorflow as tf
import pandas as pd
import numpy as np

# Monta o drive
from google.colab import drive
drive.mount('/content/drive/')

# Carrega dadosde lingua de sinais americana
meu_dir = '/content/drive/MyDrive/CNN/'

train_df = pd.read_csv(meu_dir + "sign_mnist_train.csv")
test_df = pd.read_csv(meu_dir + "sign_mnist_valid.csv")

train_df.head()

# Separa as classes
Y_train = train_df['label']
Y_test = test_df['label']

del train_df['label']
del test_df['label']

# Vetores de atributos
X_train = train_df.values
X_test = test_df.values

# Mostra as imagens
import matplotlib.pyplot as plt
plt.figure(figsize=(8,8))

num_images = 25
for i in range(num_images):
    row = X_train[i]
    #label = Y_train[i]

    image = row.reshape(28,28)
    plt.subplot(5, 5, i+1)
    #plt.title(label, fontdict={'fontsize': 30})
    plt.axis('off')
    plt.imshow(image, cmap='gray')

# Separa em treino e validação
from sklearn.model_selection import train_test_split

X_train, X_val, Y_train, Y_val = train_test_split(
    X_train, Y_train, test_size=0.2, random_state=42)

X_train.shape

np.unique(Y_val)

Y_train

# Converte as categorias para binário
num_classes = 24
Y_train = keras.utils.to_categorical(Y_train,num_classes)
Y_test = keras.utils.to_categorical(Y_test,num_classes)
Y_val = keras.utils.to_categorical(Y_val,num_classes)

# Normaliza atributo
X_train = X_train / 255
X_test = X_test / 255
X_val = X_val / 255

Y_train

Y_train[0]

# Categorical cross-entropy
y_true = [[0, 1, 0], [0, 0, 1]]
y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]
cce = tf.keras.losses.CategoricalCrossentropy()
cce(y_true,y_pred).numpy()

# Sparse Categorical cross-entropy
y_true = [1,2]
y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]
cce = tf.keras.losses.SparseCategoricalCrossentropy()
cce(y_true,y_pred).numpy()

#Shape atual
X_train.shape, X_test.shape, X_val.shape

# Reshape nas imagens
X_train = X_train.reshape(-1,28,28,1)
X_test = X_test.reshape(-1,28,28,1)
X_val = X_val.reshape(-1,28,28,1)

X_train.shape, X_test.shape, X_val.shape

num_classes

# Importa camadas adicionais
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Cria modelo CNN
model = keras.Sequential()

# Adiciona camadas convolucionais e de pooling
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())

# Adiciona camadas totalmente conectadas (Dense)
model.add(Dense(128, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

# Compila o modelo
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Exibe resumo do modelo
model.summary()

# Treina o modelo
history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_val, Y_val))


# Avalia o modelo
test_loss, test_acc = model.evaluate(X_test, Y_test)
print(f'\nTest Accuracy: {test_acc * 100:.2f}%')

# Plota a precisão e a perda no treinamento
plt.figure(figsize=(12, 4))

# Precisão
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Perda
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Exibe os gráficos
plt.show()


# monta i jashdi 
apsh, daij
